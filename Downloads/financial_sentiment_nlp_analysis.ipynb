{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## ***Natural Language Processing (NLP) on Financial Sentiment Data***"
      ],
      "metadata": {
        "id": "Avll535C9jAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1 Project Overview and Objectives**"
      ],
      "metadata": {
        "id": "2x1QdrnPBIHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project demonstrates the fundamental steps of Natural Language Processing (NLP) on real-world unstructured text data. The goal is to clean, standardize, and enrich the text to prepare it for advanced analytics, such as building a financial sentiment classifier."
      ],
      "metadata": {
        "id": "DviwYSckA6-D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Dataset Context: StockerBot Financial Tweets**"
      ],
      "metadata": {
        "id": "MPf5y_kRBYY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Source*: Kaggle:https://www.kaggle.com/datasets/davidwallach/financial-tweets\n",
        "\n",
        "*Content*: 28k+ tweets about publicly traded companies and cryptocurrencies.\n",
        "\n",
        "*Influencers*: Tweets are sourced from key financial and news sources (e.g., MarketWatch, WSJ, Jim Cramer).\n",
        "\n",
        "*Goal*: To understand public sentiment around financial markets based on influential voices.\n",
        "\n"
      ],
      "metadata": {
        "id": "sJq1xw99BELT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Core Tasks**"
      ],
      "metadata": {
        "id": "s6ReI5njEFyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will execute and explain five essential NLP techniques on the tweet data:\n",
        "\n",
        "1. Normalization: Cleaning and standardizing the text.\n",
        "\n",
        "2. Stemming: Reducing words to their root stem (fast, heuristic method).\n",
        "\n",
        "3. Lemmatization: Reducing words to their valid dictionary base form (accurate, linguistic method).\n",
        "\n",
        "4. Text Enrichment (POS Tagging): Determining the grammatical role of each word.\n",
        "\n",
        "5. Named Entity Recognition (NER): Identifying and classifying real-world entities (companies, persons, dates)."
      ],
      "metadata": {
        "id": "J1EMgshYEQ3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Environment Setup and Data Acquisition**"
      ],
      "metadata": {
        "id": "CXKPCqk3EjSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1. Installing Libraries and Downloading Resources**"
      ],
      "metadata": {
        "id": "kEuqarNPEp40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step ensures all required Python packages (Pandas, NLTK, spaCy) are installed and necessary language models are downloaded."
      ],
      "metadata": {
        "id": "5wZyYo78Es_b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDyKXTtr9OFj",
        "outputId": "45612471-8849-444d-f14b-ace9af0b1c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/12.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/12.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/12.8 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/12.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m9.2/12.8 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m12.4/12.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install nltk spacy pandas kaggle -qq\n",
        "!python -m spacy download en_core_web_sm -qq\n",
        "\n",
        "# Import necessary modules\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Download NLTK resources\n",
        "# These downloads are required for Stop Words, Tokenization, Lemmatization, and POS Tagging\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger_eng', quiet=True)\n",
        "\n",
        "\n",
        "# Initialize the advanced Spacy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Data Loading, Selection, and Sampling"
      ],
      "metadata": {
        "id": "VATHytSiLNwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('stockerbot-export.csv', encoding='utf-8', on_bad_lines='skip')\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8noHSEy5Lfbq",
        "outputId": "91b7a9ab-dd3a-4326-868c-e2fcf84b41e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        id                                               text  \\\n",
              "0      1019696670777503700  VIDEO: “I was in my office. I was minding my o...   \n",
              "1      1019709091038548000  The price of lumber $LB_F is down 22% since hi...   \n",
              "2      1019711413798035500  Who says the American Dream is dead? https://t...   \n",
              "3      1019716662587740200  Barry Silbert is extremely optimistic on bitco...   \n",
              "4      1019718460287389700  How satellites avoid attacks and space junk wh...   \n",
              "...                    ...                                                ...   \n",
              "28259  1019730088617635800         $FB : 29234a9c-7f08-4d5a-985f-cb1a5554ecf9   \n",
              "28260  1019730115524288500  【仮想通貨】ビットコインの価格上昇、８０万円台回復　約１カ月半ぶり　　　　　　$BTC ht...   \n",
              "28261  1019730115805184000  RT @invest_in_hd: 'Nuff said!  $TEL #telcoin #...   \n",
              "28262  1019730117252341800  【仮想通貨】ビットコインの価格上昇、８０万円台回復　約１カ月半ぶり　　　　　　$BTC ht...   \n",
              "28263  1019730146180419600  Stellar $XLM price: $0.297852 Binance registra...   \n",
              "\n",
              "                            timestamp           source symbols  \\\n",
              "0      Wed Jul 18 21:33:26 +0000 2018     GoldmanSachs      GS   \n",
              "1      Wed Jul 18 22:22:47 +0000 2018       StockTwits       M   \n",
              "2      Wed Jul 18 22:32:01 +0000 2018        TheStreet     AIG   \n",
              "3      Wed Jul 18 22:52:52 +0000 2018      MarketWatch     BTC   \n",
              "4      Wed Jul 18 23:00:01 +0000 2018           Forbes    ORCL   \n",
              "...                               ...              ...     ...   \n",
              "28259  Wed Jul 18 23:46:13 +0000 2018       test5f1798      FB   \n",
              "28260  Wed Jul 18 23:46:19 +0000 2018  keizai_toushi17     BTC   \n",
              "28261  Wed Jul 18 23:46:19 +0000 2018            iad81     BTC   \n",
              "28262  Wed Jul 18 23:46:20 +0000 2018  O8viWMyrCV6cBOZ     BTC   \n",
              "28263  Wed Jul 18 23:46:27 +0000 2018     Descendent92     AMP   \n",
              "\n",
              "              company_names  \\\n",
              "0         The Goldman Sachs   \n",
              "1                    Macy's   \n",
              "2                  American   \n",
              "3                   Bitcoin   \n",
              "4                    Oracle   \n",
              "...                     ...   \n",
              "28259              Facebook   \n",
              "28260               Bitcoin   \n",
              "28261               Bitcoin   \n",
              "28262               Bitcoin   \n",
              "28263  Ameriprise Financial   \n",
              "\n",
              "                                                     url  verified  \n",
              "0      https://twitter.com/i/web/status/1019696670777...      True  \n",
              "1      https://twitter.com/i/web/status/1019709091038...      True  \n",
              "2                                https://buff.ly/2L3kmc4      True  \n",
              "3      https://twitter.com/i/web/status/1019716662587...      True  \n",
              "4                         http://on.forbes.com/6013DqDDU      True  \n",
              "...                                                  ...       ...  \n",
              "28259                                                NaN     False  \n",
              "28260             http://keizai-toushi-navi.com/?p=26838     False  \n",
              "28261  https://twitter.com/CRYPTOVERLOAD/status/10178...     False  \n",
              "28262         http://true.velvet.jp/monexx/archives/2357     False  \n",
              "28263  https://twitter.com/i/web/status/1019730146180...     False  \n",
              "\n",
              "[28264 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff069ee2-e93e-44d3-b0ea-6963b381d4a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>source</th>\n",
              "      <th>symbols</th>\n",
              "      <th>company_names</th>\n",
              "      <th>url</th>\n",
              "      <th>verified</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1019696670777503700</td>\n",
              "      <td>VIDEO: “I was in my office. I was minding my o...</td>\n",
              "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
              "      <td>GoldmanSachs</td>\n",
              "      <td>GS</td>\n",
              "      <td>The Goldman Sachs</td>\n",
              "      <td>https://twitter.com/i/web/status/1019696670777...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1019709091038548000</td>\n",
              "      <td>The price of lumber $LB_F is down 22% since hi...</td>\n",
              "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
              "      <td>StockTwits</td>\n",
              "      <td>M</td>\n",
              "      <td>Macy's</td>\n",
              "      <td>https://twitter.com/i/web/status/1019709091038...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1019711413798035500</td>\n",
              "      <td>Who says the American Dream is dead? https://t...</td>\n",
              "      <td>Wed Jul 18 22:32:01 +0000 2018</td>\n",
              "      <td>TheStreet</td>\n",
              "      <td>AIG</td>\n",
              "      <td>American</td>\n",
              "      <td>https://buff.ly/2L3kmc4</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1019716662587740200</td>\n",
              "      <td>Barry Silbert is extremely optimistic on bitco...</td>\n",
              "      <td>Wed Jul 18 22:52:52 +0000 2018</td>\n",
              "      <td>MarketWatch</td>\n",
              "      <td>BTC</td>\n",
              "      <td>Bitcoin</td>\n",
              "      <td>https://twitter.com/i/web/status/1019716662587...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1019718460287389700</td>\n",
              "      <td>How satellites avoid attacks and space junk wh...</td>\n",
              "      <td>Wed Jul 18 23:00:01 +0000 2018</td>\n",
              "      <td>Forbes</td>\n",
              "      <td>ORCL</td>\n",
              "      <td>Oracle</td>\n",
              "      <td>http://on.forbes.com/6013DqDDU</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28259</th>\n",
              "      <td>1019730088617635800</td>\n",
              "      <td>$FB : 29234a9c-7f08-4d5a-985f-cb1a5554ecf9</td>\n",
              "      <td>Wed Jul 18 23:46:13 +0000 2018</td>\n",
              "      <td>test5f1798</td>\n",
              "      <td>FB</td>\n",
              "      <td>Facebook</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28260</th>\n",
              "      <td>1019730115524288500</td>\n",
              "      <td>【仮想通貨】ビットコインの価格上昇、８０万円台回復　約１カ月半ぶり　　　　　　$BTC ht...</td>\n",
              "      <td>Wed Jul 18 23:46:19 +0000 2018</td>\n",
              "      <td>keizai_toushi17</td>\n",
              "      <td>BTC</td>\n",
              "      <td>Bitcoin</td>\n",
              "      <td>http://keizai-toushi-navi.com/?p=26838</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28261</th>\n",
              "      <td>1019730115805184000</td>\n",
              "      <td>RT @invest_in_hd: 'Nuff said!  $TEL #telcoin #...</td>\n",
              "      <td>Wed Jul 18 23:46:19 +0000 2018</td>\n",
              "      <td>iad81</td>\n",
              "      <td>BTC</td>\n",
              "      <td>Bitcoin</td>\n",
              "      <td>https://twitter.com/CRYPTOVERLOAD/status/10178...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28262</th>\n",
              "      <td>1019730117252341800</td>\n",
              "      <td>【仮想通貨】ビットコインの価格上昇、８０万円台回復　約１カ月半ぶり　　　　　　$BTC ht...</td>\n",
              "      <td>Wed Jul 18 23:46:20 +0000 2018</td>\n",
              "      <td>O8viWMyrCV6cBOZ</td>\n",
              "      <td>BTC</td>\n",
              "      <td>Bitcoin</td>\n",
              "      <td>http://true.velvet.jp/monexx/archives/2357</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28263</th>\n",
              "      <td>1019730146180419600</td>\n",
              "      <td>Stellar $XLM price: $0.297852 Binance registra...</td>\n",
              "      <td>Wed Jul 18 23:46:27 +0000 2018</td>\n",
              "      <td>Descendent92</td>\n",
              "      <td>AMP</td>\n",
              "      <td>Ameriprise Financial</td>\n",
              "      <td>https://twitter.com/i/web/status/1019730146180...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28264 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff069ee2-e93e-44d3-b0ea-6963b381d4a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff069ee2-e93e-44d3-b0ea-6963b381d4a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff069ee2-e93e-44d3-b0ea-6963b381d4a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3c83647a-3d94-4fb8-8fdb-7fe44eaed125\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c83647a-3d94-4fb8-8fdb-7fe44eaed125')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3c83647a-3d94-4fb8-8fdb-7fe44eaed125 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3181b669-b562-438f-9ec4-5af6e76e3e5d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3181b669-b562-438f-9ec4-5af6e76e3e5d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 28264,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 991191115973735,\n        \"min\": 967109381098758100,\n        \"max\": 1019743063328030700,\n        \"num_unique_values\": 28263,\n        \"samples\": [\n          1018928405453135900,\n          1019587553551372300,\n          1018876544587063300\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25685,\n        \"samples\": [\n          \"$UA https://t.co/Ss6YnaTzXu\",\n          \"Analysts at Morgan Stanley Reiterate their Past \\u2018\\\"Equal-Weight\\\"\\u2019 rating on Shares Waters $WAT Set a $205 Target Pr\\u2026 https://t.co/eyL0pxrhQB\",\n          \"RT @Idera_Pharma: $IDRA $BMY $MRK  Orphan drug designation in 2017 and Fast track designation in 2018. Ongoing meaningful clinical trials i\\u2026\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 26777,\n        \"samples\": [\n          \"Sun Jul 15 15:19:57 +0000 2018\",\n          \"Tue Jul 17 17:25:10 +0000 2018\",\n          \"Wed Jul 18 10:39:43 +0000 2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5879,\n        \"samples\": [\n          \"HawkinsTammy\",\n          \"codenamejason\",\n          \"africantabs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"symbols\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 453,\n        \"samples\": [\n          \"SLB\",\n          \"HCA\",\n          \"CTL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company_names\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 461,\n        \"samples\": [\n          \"Northrop Grumman Corporation\",\n          \"Xylem Inc.\",\n          \"HCA Healthcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17814,\n        \"samples\": [\n          \"https://twitter.com/i/web/status/1019701180589432833\",\n          \"https://seekingalpha.com/article/4188187-kimco-good-yield-bad-dividend-quality-pass?source=feed_f\",\n          \"http://theolympiareport.com/?p=928936\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verified\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the 'text' column, which contains the tweet content\n",
        "text_column = 'text' # Confirmed column name for tweet content\n",
        "\n",
        "# Select the text column, drop missing values, and take a random sample of 1000 tweets.\n",
        "df_text = data[text_column].astype(str).dropna().sample(n=1000, random_state=42).reset_index(drop=True)\n",
        "sample_tweets_to_view = df_text.head(4).tolist()\n",
        "sample_tweet = df_text.iloc[3]\n",
        "\n",
        "print(f\"\\nDataset successfully loaded. Total rows: {len(data)}\")\n",
        "print(f\"Total rows in sample for analysis: {len(df_text)}\")\n",
        "print(\"\\n--- 4 Sample Tweets for Preview ---\")\n",
        "for i, tweet in enumerate(sample_tweets_to_view):\n",
        "    print(f\"Tweet {i+1}: {tweet}\")\n",
        "\n",
        "print(f\"\\n--- Selected Tweet (Tweet 1) for NLP Demonstration --- \\n{sample_tweet}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLrtLrkmMIPN",
        "outputId": "6f6757a2-afff-46d2-8ed9-25db5430b16f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset successfully loaded. Total rows: 28264\n",
            "Total rows in sample for analysis: 1000\n",
            "\n",
            "--- 4 Sample Tweets for Preview ---\n",
            "Tweet 1: Some candidates for you to short:  $CHKP $XOM $CBS $MRK\n",
            "Tweet 2: https://t.co/9VjKMnGXvX $CVNA $DAL $DISCA $MU $TKC https://t.co/wkeFqrTQxF\n",
            "Tweet 3: As Accenture Plc Ireland $ACN Market Value Declined Morgan Stanley Trimmed Position - https://t.co/IFHuXpSSE9\n",
            "Tweet 4: Are Analysts Bullish about Campbell Soup Company $CPB after last week? https://t.co/BcMiRuN8uF\n",
            "\n",
            "--- Selected Tweet (Tweet 1) for NLP Demonstration --- \n",
            "Are Analysts Bullish about Campbell Soup Company $CPB after last week? https://t.co/BcMiRuN8uF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Natural Language Processing Technique**"
      ],
      "metadata": {
        "id": "0d-Gnap-N9SA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1. Normalization**"
      ],
      "metadata": {
        "id": "g7U-N3J1OHqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization is the foundational step in text preprocessing. Its objective is to reduce variation and noise, leading to a more efficient and accurate analysis.\n",
        "\n",
        "1. Lowercasing: All text is converted to lowercase, treating 'Apple', 'apple', and 'APPLE' as the same token.\n",
        "\n",
        "2. Noise Removal: In financial tweets, this means stripping away elements like URLs, mentions (@user), hashtags (#finance), and crucially, stock tickers ($TSLA) which, while important contextually, are removed here to focus on the surrounding verbal sentiment.\n",
        "\n",
        "3. Stop Word Removal: Common, non-essential words (e.g., 'the', 'a', 'is') are filtered out using the NLTK English stop word list, significantly reducing the volume of data without losing core meaning."
      ],
      "metadata": {
        "id": "3ScuK4lYOG3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the comprehensive normalization function\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    # Remove URLs, mentions, hashtags, and stock tickers (e.g., $TSLA)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'@\\w+|#\\w+|\\$\\w+', '', text)\n",
        "    # Tokenization: Splitting the text into individual words/units\n",
        "    tokens = word_tokenize(text)\n",
        "    # Stop Word Removal & Punctuation Cleanup\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Keep only alphanumeric words that are NOT stop words\n",
        "    normalized_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return normalized_tokens\n",
        "\n",
        "normalized_output = normalize_text(sample_tweet)\n",
        "\n",
        "print(f\"Original Tweet: {sample_tweet}\")\n",
        "print(\"\\n--- Normalization Results ---\")\n",
        "print(f\"Tokens after Normalization: {normalized_output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31abnRgQOu51",
        "outputId": "6e77606d-8720-4de6-f988-aa3aa319ea37"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tweet: Are Analysts Bullish about Campbell Soup Company $CPB after last week? https://t.co/BcMiRuN8uF\n",
            "\n",
            "--- Normalization Results ---\n",
            "Tokens after Normalization: ['analysts', 'bullish', 'campbell', 'soup', 'company', 'last', 'week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2. Stemming**"
      ],
      "metadata": {
        "id": "M73QjJGNP2EY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming is a simple, rule-based approach to morphological analysis. It employs a set of heuristic rules (like removing common suffixes) to truncate words and find their root stem. We use the Porter Stemmer, one of the most widely adopted algorithms.\n",
        "\n",
        "*   Benefit: It is computationally fast and highly effective for reducing word  variations.\n",
        "\n",
        "*   Limitation: The resulting stem may often be a non-dictionary word (e.g., 'univers' for 'university'), which can decrease linguistic accuracy."
      ],
      "metadata": {
        "id": "kijFs84hMHhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will use the tokens obtained from the Normalization step\n",
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in normalized_output]\n",
        "\n",
        "print(f\"Normalized Tokens: {normalized_output}\")\n",
        "print(\"\\n--- Stemming Results ---\")\n",
        "print(f\"Words after Stemming: {stemmed_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvS9F9q_QXgz",
        "outputId": "1edc952c-fb80-4d57-e3c1-8b7a80d9d298"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Tokens: ['analysts', 'bullish', 'campbell', 'soup', 'company', 'last', 'week']\n",
            "\n",
            "--- Stemming Results ---\n",
            "Words after Stemming: ['analyst', 'bullish', 'campbel', 'soup', 'compani', 'last', 'week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3. Lemmatization**"
      ],
      "metadata": {
        "id": "jJ_SMVlFQtaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization is a sophisticated, vocabulary-aware technique that uses a dictionary lookup and morphological analysis to reduce a word to its true base form, or lemma.\n",
        "\n",
        "*   Benefit: The output is always a valid word (e.g., 'better' → 'good', 'went' → 'go'). This provides a higher level of linguistic accuracy than stemming.\n",
        "\n",
        "*   Application in Finance: It is crucial for sentiment analysis, ensuring that words expressing different tenses or degrees (e.g., 'rising', 'rose', 'risen') are consistently mapped to the base form 'rise'."
      ],
      "metadata": {
        "id": "D9zpVgmOQqbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the tokens obtained from the Normalization step\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Lemmatization is often more accurate when the POS tag is provided, but we use the default (noun) here.\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in normalized_output]\n",
        "\n",
        "print(f\"Normalized Tokens: {normalized_output}\")\n",
        "print(\"\\n--- Lemmatization Results ---\")\n",
        "print(f\"Words after Lemmatization: {lemmatized_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avt24VgoRDAS",
        "outputId": "1240c155-6ae6-4f50-8fc3-317390b57700"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Tokens: ['analysts', 'bullish', 'campbell', 'soup', 'company', 'last', 'week']\n",
            "\n",
            "--- Lemmatization Results ---\n",
            "Words after Lemmatization: ['analyst', 'bullish', 'campbell', 'soup', 'company', 'last', 'week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4. Text Enrichment / Augmentation (Part-of-Speech Tagging)**"
      ],
      "metadata": {
        "id": "yl2hMdPlR0__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part-of-Speech (POS) Tagging is a method of Text Enrichment that assigns a grammatical category (e.g., Noun, Verb, Adjective) to every token. We use the NLTK tagger which employs the Penn Treebank tag set.\n",
        "\n",
        "* Value: This process is essential for disambiguation and feature engineering. For instance, in the sentence \"The stock is trading down,\" the word 'stock' is tagged as a Noun (NN). In the sentence \"We must stock up on cash,\" 'stock' is tagged as a Verb (VB). This contextual information is vital for training accurate text classifiers."
      ],
      "metadata": {
        "id": "CrjKgwjGR0X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use NLTK POS Tagger on the original tokens (before stop word removal)\n",
        "raw_tokens = word_tokenize(sample_tweet)\n",
        "pos_tags = nltk.pos_tag(raw_tokens)\n",
        "\n",
        "print(f\"Original Tokens: {raw_tokens}\")\n",
        "print(\"\\n--- POS Tagging Results ---\")\n",
        "print(f\"POS Tags (Token, Tag): {pos_tags}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emcL4I_hSGmZ",
        "outputId": "1d594c78-579b-4c6b-b0c9-faa53fe1e541"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens: ['Are', 'Analysts', 'Bullish', 'about', 'Campbell', 'Soup', 'Company', '$', 'CPB', 'after', 'last', 'week', '?', 'https', ':', '//t.co/BcMiRuN8uF']\n",
            "\n",
            "--- POS Tagging Results ---\n",
            "POS Tags (Token, Tag): [('Are', 'NNP'), ('Analysts', 'NNS'), ('Bullish', 'VBP'), ('about', 'IN'), ('Campbell', 'NNP'), ('Soup', 'NNP'), ('Company', 'NNP'), ('$', '$'), ('CPB', 'NNP'), ('after', 'IN'), ('last', 'JJ'), ('week', 'NN'), ('?', '.'), ('https', 'NN'), (':', ':'), ('//t.co/BcMiRuN8uF', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5. Named Entity Recognition (NER)**"
      ],
      "metadata": {
        "id": "GMH-V9eNTaTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named Entity Recognition (NER) is a key technique for structuring unstructured text. It automatically locates and classifies sequences of words that refer to real-world objects, such as people, organizations, dates, and locations. We utilize the powerful spaCy library for this task.\n",
        "\n",
        "* Value in Finance: NER is critical for quickly identifying:\n",
        "\n",
        "  *  ORG (Organizations): Names of companies (if not already tagged by the ticker).\n",
        "\n",
        "  *  PERSON: Names of influencers or executives (e.g., Elon Musk, Jim Cramer).\n",
        "\n",
        "  *  DATE/CARDINAL: Specific timeframes, quantities, or prices mentioned."
      ],
      "metadata": {
        "id": "hFaOXCaxTeQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the Spacy model for powerful NER\n",
        "doc = nlp(sample_tweet)\n",
        "\n",
        "# Extract and label the entities\n",
        "named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "print(f\"Sample Tweet: {sample_tweet}\")\n",
        "print(\"\\n--- NER Results ---\")\n",
        "print(f\"Named Entities (Entity, Type): {named_entities}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWPmwaJZT18p",
        "outputId": "5180c8be-9f70-4c32-a22d-7783be5c5bce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Tweet: Are Analysts Bullish about Campbell Soup Company $CPB after last week? https://t.co/BcMiRuN8uF\n",
            "\n",
            "--- NER Results ---\n",
            "Named Entities (Entity, Type): [('Campbell Soup Company', 'ORG'), ('CPB', 'ORG'), ('last week', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Conclusion and Next Steps**"
      ],
      "metadata": {
        "id": "YttIgQ5gUMNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook successfully demonstrated the five core NLP techniques, cleaning and enriching the financial sentiment data. The processed tokens and extracted entities are now ready for the next phase of analysis, which typically involves Feature Engineering (e.g., creating TF-IDF vectors) and Model Building (e.g., training a machine learning classifier for sentiment prediction)."
      ],
      "metadata": {
        "id": "g3lHS2PqUHkQ"
      }
    }
  ]
}